{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ca1cd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated molecule file path: outputs/eegsde_qm9_fingerprint/l_0.5/samples/70912/70912_samples.xyz\n",
      "Generated molecule file path: outputs/eegsde_qm9_fingerprint/l_0.5/samples/70912/70912_samples.xyz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 'a' is fp_1024 of desired molecules\n",
    "a = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, \n",
    "     1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "# Convert the list to a string representation\n",
    "a_str = ','.join(str(int(bit)) for bit in a) \n",
    "\n",
    "# Define the command and arguments in a list\n",
    "command = [\n",
    "    'python', 'run_EEGSDE_fingerprint.py',\n",
    "    '--exp_name', 'eegsde_qm9_fingerprint',\n",
    "    '--l', '0.5',\n",
    "    '--generators_path', 'pretrained_models/cEDM_fingerprint/generative_model_ema_1340.npy',\n",
    "    '--args_generators_path', 'pretrained_models/cEDM_fingerprint/args_1340.pickle',\n",
    "    '--energy_path', 'pretrained_models/predict_fingerprint/model_ema_1750.npy',\n",
    "    '--args_energy_path', 'pretrained_models/predict_fingerprint/args_1750.pickle',\n",
    "    '--batch_size', '50',\n",
    "    '--save', 'True',\n",
    "    '--fp_1024', a_str  # Passing the string representation of the list\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print('Command failed')\n",
    "    print(result.stderr)\n",
    "else:\n",
    "    output_lines = result.stdout.split('\\n')\n",
    "    for line in output_lines:\n",
    "        if line.strip().endswith('_samples.xyz'):\n",
    "            print(f\"Generated molecule file path: {line}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d8251e",
   "metadata": {},
   "source": [
    "## Initialize Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72e8af40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chao/anaconda3/envs/EEGSDE/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:173: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  FutureWarning,\n",
      "Some weights of the model checkpoint at t5-large were not used when initializing T5EncoderModel: ['decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.final_layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1073,  0.0006, -0.0436,  ...,  0.0008,  0.0665,  0.0104]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "import torch\n",
    "\n",
    "# Load the T5 tokenizer and encoder model\n",
    "model_name = \"t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5EncoderModel.from_pretrained(model_name)\n",
    "\n",
    "# Define the input sentence\n",
    "sentence = \"The molecule is an O-acylcarnitine having acetyl as the acyl substituent. It has a role as a human metabolite. It derives from an acetic acid. It is a conjugate base of an O-acetylcarnitinium.\"\n",
    "\n",
    "# Tokenize the sentence and convert it to input_ids\n",
    "input_ids = tokenizer.encode(sentence, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Generate the encoding (hidden states)\n",
    "with torch.no_grad():\n",
    "    encoding = model(input_ids).last_hidden_state\n",
    "\n",
    "# Extract the 1024-length vector\n",
    "sentence_vector = torch.mean(encoding, dim=1)  # Reduce the sequence dimension to 1\n",
    "\n",
    "print(sentence_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3016e2f",
   "metadata": {},
   "source": [
    "## Load attention based fingerprint prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "657b67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "class CustomTransformer(nn.Module):\n",
    "    def __init__(self, input_embed_size, transformer_embed_size, num_heads, num_layers, output_size, dropout_rate=0.1):\n",
    "        super(CustomTransformer, self).__init__()\n",
    "        \n",
    "        # GRU for dimensionality reduction: 1024 -> 128\n",
    "        self.gru_down1 = nn.GRU(input_size=input_embed_size, hidden_size=512, batch_first=True)\n",
    "        self.batchnorm_down1 = nn.BatchNorm1d(num_features=512)\n",
    "        self.gru_down2 = nn.GRU(input_size=512, hidden_size=256, batch_first=True)\n",
    "        self.batchnorm_down2 = nn.BatchNorm1d(num_features=256)\n",
    "        self.gru_down3 = nn.GRU(input_size=256, hidden_size=128, batch_first=True)\n",
    "        self.batchnorm_down3 = nn.BatchNorm1d(num_features=transformer_embed_size)\n",
    "        \n",
    "        # Transformer Encoder setup\n",
    "        self.transformer_layers = nn.TransformerEncoderLayer(d_model=transformer_embed_size, nhead=num_heads, dropout=dropout_rate)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_layers, num_layers=num_layers)\n",
    "        \n",
    "        # GRU for dimensionality increasing: 128 -> 1024\n",
    "        self.gru_up1 = nn.GRU(input_size=transformer_embed_size, hidden_size=256, batch_first=True)\n",
    "        self.batchnorm_up1 = nn.BatchNorm1d(num_features=256)\n",
    "        self.gru_up2 = nn.GRU(input_size=256, hidden_size=512, batch_first=True)\n",
    "        self.batchnorm_up2 = nn.BatchNorm1d(num_features=512)\n",
    "        self.gru_up3 = nn.GRU(input_size=512, hidden_size=output_size, batch_first=True)\n",
    "        self.batchnorm_up3 = nn.BatchNorm1d(num_features=output_size)\n",
    "        \n",
    "        \n",
    "        # Final output layer\n",
    "        self.fc_out = nn.Linear(output_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "    # Ensure x is 3D (batch_size, seq_len, input_embed_size)\n",
    "        if x.dim() == 2:\n",
    "        # If x is 2D (batch_size, input_embed_size), unsqueeze to make it 3D\n",
    "            x = x.unsqueeze(1)\n",
    "    \n",
    "    # GRU down: No need to transpose here as GRU expects input of shape (batch, seq_len, feature)\n",
    "        x, _ = self.gru_down1(x)\n",
    "    \n",
    "    # Batch normalization across the sequence dimension\n",
    "    # Transpose to match BatchNorm1d's expectation of (batch_size, num_features, seq_len)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.batchnorm_down1(x)\n",
    "        x = x.transpose(1, 2)  # Transpose back to (batch, seq_len, feature) for transformer\n",
    "        x, _ = self.gru_down2(x)\n",
    "    \n",
    "    # Batch normalization across the sequence dimension\n",
    "    # Transpose to match BatchNorm1d's expectation of (batch_size, num_features, seq_len)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.batchnorm_down2(x)\n",
    "        x = x.transpose(1, 2)# Transpose back to (batch, seq_len, feature) for transformer\n",
    "    \n",
    "    \n",
    "    \n",
    "        x, _ = self.gru_down3(x)\n",
    "    \n",
    "    # Batch normalization across the sequence dimension\n",
    "    # Transpose to match BatchNorm1d's expectation of (batch_size, num_features, seq_len)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.batchnorm_down3(x)\n",
    "        x = x.transpose(1, 2)  # Transpose back to (batch, seq_len, feature) for transformer\n",
    "    # Transformer encoder expects input of shape (seq_len, batch, feature), so we need to permute\n",
    "        x = x.permute(1, 0, 2)\n",
    "        \n",
    "        \n",
    "        transformer_output = self.transformer_encoder(x)\n",
    "        transformer_output = transformer_output.permute(1, 0, 2)  # Permute back to (batch, seq_len, feature)\n",
    "    \n",
    "    # GRU up\n",
    "        x, _ = self.gru_up1(transformer_output)\n",
    "    \n",
    "    # Apply BatchNorm1d again after GRU up, ensure to transpose correctly\n",
    "        x = x.transpose(1, 2)  # Corrected transpose to apply BatchNorm1d\n",
    "        x = self.batchnorm_up1(x)\n",
    "        x = x.transpose(1, 2)  # Transpose back\n",
    "        \n",
    "        x, _ = self.gru_up2(x)\n",
    "    \n",
    "    # Apply BatchNorm1d again after GRU up, ensure to transpose correctly\n",
    "        x = x.transpose(1, 2)  # Corrected transpose to apply BatchNorm1d\n",
    "        x = self.batchnorm_up2(x)\n",
    "        x = x.transpose(1, 2)  # Transpose back\n",
    "        \n",
    "        x, _ = self.gru_up3(x)\n",
    "    \n",
    "    # Apply BatchNorm1d again after GRU up, ensure to transpose correctly\n",
    "        x = x.transpose(1, 2)  # Corrected transpose to apply BatchNorm1d\n",
    "        x = self.batchnorm_up3(x)\n",
    "        x = x.transpose(1, 2)  # Transpose back\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Assuming you want to apply the fully connected layer across all sequence elements\n",
    "    # Flatten the output from GRU up for the fully connected layer\n",
    "        x = x.reshape(x.shape[0], -1)  # Flatten while keeping the batch size dimension\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "    \n",
    "    # Apply ReLU and sigmoid\n",
    "        #x = F.relu(x)\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d81b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1073,  0.0006, -0.0436,  ...,  0.0008,  0.0665,  0.0104]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Parameters\n",
    "input_embed_size = 1024  # Original input embedding size\n",
    "transformer_embed_size = 128  # Reduced embedding size for transformer\n",
    "num_heads = 128  # Adjusted to fit the reduced embedding size\n",
    "num_layers = 1\n",
    "output_size = 1024  # Output size to match the original embedding size\n",
    "dropout_rate = 0.1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sentence_vector=sentence_vector.to(device)\n",
    "# Function to load the model checkpoint\n",
    "def load_model(checkpoint_path, model, device):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model\n",
    "def predict_fingerprint(input_vectors, model, device):\n",
    "    model.eval()\n",
    "    # \n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Pass only the input_ids tensor to your custom model\n",
    "        outputs = model(input_vectors)\n",
    "        #predictions = outputs.sigmoid()  # Apply sigmoid to the output logits\n",
    "        predictions = (outputs> 0.5).int()  # Apply threshold to get binary fingerprint\n",
    "    \n",
    "    #return predictions.squeeze().cpu().numpy()\n",
    "    return predictions\n",
    "model = CustomTransformer(input_embed_size, transformer_embed_size, num_heads, num_layers, output_size, dropout_rate).to(device)\n",
    "\n",
    "# Rest of your code remains the same\n",
    "checkpoint_path = '/home/chao/3dmolgen/model_checkpoint_GT1G.pth.tar'\n",
    "#checkpoint_path = \"model_checkpoint_GRU.pth.tar\"\n",
    "print(sentence_vector)\n",
    "# Load the model from checkpoint\n",
    "model = load_model(checkpoint_path, model, device)\n",
    "predicted_fingerprint = predict_fingerprint(sentence_vector, model, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "142bb05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openbabel\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import QED, Crippen, Descriptors, rdMolDescriptors\n",
    "\n",
    "def xyz_to_smiles(xyz_file):\n",
    "    obConversion = openbabel.OBConversion()\n",
    "    obConversion.SetInFormat(\"xyz\")\n",
    "\n",
    "    mol = openbabel.OBMol()\n",
    "    obConversion.ReadFile(mol, xyz_file)  # Read the molecule from file\n",
    "\n",
    "    obConversion.SetOutFormat(\"smi\")\n",
    "    smiles = obConversion.WriteString(mol)  # Convert to SMILES\n",
    "\n",
    "    return smiles.strip()\n",
    "\n",
    "def get_largest_fragment(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if not mol:\n",
    "        return None, \"Invalid SMILES string.\"\n",
    "    \n",
    "    fragments = Chem.GetMolFrags(mol, asMols=True)\n",
    "    if not fragments:\n",
    "        return None, \"No fragments found.\"\n",
    "\n",
    "    largest_fragment = max(fragments, key=lambda frag: frag.GetNumAtoms())\n",
    "    return largest_fragment, \"\"\n",
    "\n",
    "def check_molecule_sanity(mol):\n",
    "    try:\n",
    "        Chem.SanitizeMol(mol)\n",
    "        return \"Molecule is chemically valid.\"\n",
    "    except Exception as e:\n",
    "        return f\"Sanity check failed: {e}\"\n",
    "\n",
    "def compute_properties(mol):\n",
    "    properties = {}\n",
    "    properties['QED'] = QED.qed(mol)\n",
    "    properties['LogP'] = Crippen.MolLogP(mol)\n",
    "    properties['MolWt'] = Descriptors.MolWt(mol)\n",
    "    properties['SA_Score'] = rdMolDescriptors.CalcNumRotatableBonds(mol)\n",
    "    return properties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e116a",
   "metadata": {},
   "source": [
    "## Cmd for running Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a198327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "command_template = [\n",
    "    'python', 'run_EEGSDE_fingerprint.py',\n",
    "    '--exp_name', 'eegsde_qm9_fingerprint',\n",
    "    '--l', '0.5',\n",
    "    '--generators_path', 'pretrained_models/cEDM_fingerprint/generative_model_ema_1340.npy',\n",
    "    '--args_generators_path', 'pretrained_models/cEDM_fingerprint/args_1340.pickle',\n",
    "    '--energy_path', 'pretrained_models/predict_fingerprint/model_ema_1750.npy',\n",
    "    '--args_energy_path', 'pretrained_models/predict_fingerprint/args_1750.pickle',\n",
    "    '--batch_size', '50',\n",
    "    '--save', 'True'\n",
    "    '--fp_1024', a_str\n",
    "    # '--fp_1024' will be appended in _evaluate\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e0fd5",
   "metadata": {},
   "source": [
    "## NSGA Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9bfa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [02:11:50] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "[02:11:50] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "RDKit ERROR: [02:12:41] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[02:12:41] Explicit valence for atom # 3 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "n_gen  |  n_eval  | n_nds  |      eps      |   indicator  \n",
      "==========================================================\n",
      "     1 |       10 |      1 |             - |             -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [02:16:09] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "[02:16:09] Explicit valence for atom # 4 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2 |       20 |      1 |  0.000000E+00 |             f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [02:18:08] Explicit valence for atom # 15 C, 5, is greater than permitted\n",
      "[02:18:08] Explicit valence for atom # 15 C, 5, is greater than permitted\n",
      "RDKit ERROR: [02:18:46] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[02:18:46] Explicit valence for atom # 6 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3 |       30 |      1 |  1.0000028994 |         ideal\n",
      "     4 |       40 |      1 |  0.000000E+00 |             f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [02:22:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:22:45] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit WARNING: [02:22:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:22:45] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     5 |       50 |      1 |  0.000000E+00 |             f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [02:27:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[02:27:25] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     6 |       60 |      1 |  0.000000E+00 |             f\n",
      "     7 |       70 |      1 |  0.000000E+00 |             f\n",
      "     8 |       80 |      1 |  0.000000E+00 |             f\n",
      "     9 |       90 |      1 |  0.000000E+00 |             f\n",
      "    10 |      100 |      1 |  0.000000E+00 |             f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [02:42:22] Explicit valence for atom # 7 N, 4, is greater than permitted\n",
      "[02:42:22] Explicit valence for atom # 7 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    11 |      110 |      1 |  0.000000E+00 |             f\n",
      "    12 |      120 |      1 |  0.000000E+00 |             f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [02:48:19] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "[02:48:19] Explicit valence for atom # 4 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    13 |      130 |      1 |  0.000000E+00 |             f\n",
      "    14 |      140 |      1 |  0.000000E+00 |             f\n",
      "    15 |      150 |      2 |  0.000000E+00 |             f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [02:54:28] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[02:54:28] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "RDKit ERROR: [02:55:03] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[02:55:03] Explicit valence for atom # 1 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    16 |      160 |      2 |  0.000000E+00 |             f\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from pymoo.core.problem import Problem\n",
    "\n",
    "# Assuming the CustomTransformer and other necessary functions are defined above\n",
    "\n",
    "class MolecularOptimizationProblem(Problem):\n",
    "    def __init__(self, vector_size, original_properties, command_template, model, device, *args, **kwargs):\n",
    "        super().__init__(n_var=vector_size , n_obj=1, n_constr=0, xl=0, xu=1, *args, **kwargs)\n",
    "        self.original_properties = original_properties\n",
    "        self.command_template = command_template\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.evaluation_counter = 0\n",
    "\n",
    "    def _evaluate(self, X, out, *args, **kwargs):\n",
    "        F = np.empty((len(X), 1))  # Preallocate F with the correct shape\n",
    "\n",
    "        for i, x in enumerate(X):\n",
    "            self.evaluation_counter += 1\n",
    "            #print(f\"Evaluating solution {self.evaluation_counter}...\")\n",
    "            #print(x)\n",
    "\n",
    "            try:\n",
    "                sentence_vector = torch.tensor(x, dtype=torch.float32).to(self.device).unsqueeze(0)\n",
    "                fingerprint_vector = predict_fingerprint(sentence_vector, self.model, self.device)\n",
    "                a_str = ','.join(str(int(bit)) for bit in fingerprint_vector.squeeze().tolist())\n",
    "\n",
    "                command = self.command_template[:-1] + ['--fp_1024', a_str]\n",
    "                result = subprocess.run(command, capture_output=True, text=True)\n",
    "                \n",
    "                if result.returncode != 0:\n",
    "                    raise Exception(f'Command failed: {result.stderr}')\n",
    "\n",
    "                xyz_file_path = 'outputs/eegsde_qm9_fingerprint/l_0.5/samples/70912/70912_samples.xyz/samples_000.txt'\n",
    "                smiles = xyz_to_smiles(xyz_file_path)\n",
    "                largest_fragment, _ = get_largest_fragment(smiles)\n",
    "\n",
    "                if largest_fragment:\n",
    "                    properties = compute_properties(largest_fragment)\n",
    "                    qed_difference = (properties['QED'] - self.original_properties['QED']) ** 2\n",
    "                    sa_score = properties['SA_Score']\n",
    "                    loss = sa_score + qed_difference\n",
    "                else:\n",
    "                    loss = np.inf\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error during evaluation: {e}\")\n",
    "                loss = np.inf\n",
    "\n",
    "            F[i, 0] = loss\n",
    "\n",
    "        out[\"F\"] = F\n",
    "\n",
    "# Initialize model, device, and other parameters outside this class definition\n",
    "# model = load_model(checkpoint_path, CustomTransformer(...), device)\n",
    "original_properties = {'QED': 0.4682894606480587, 'LogP': -0.7110000000000001, 'MolWt': 156.137, 'SA_Score': 1}\n",
    "\n",
    "vector_size=1024\n",
    "# Initialize the problem\n",
    "problem = MolecularOptimizationProblem(vector_size, original_properties, command_template, model, device)\n",
    "\n",
    "# Continue with NSGA-II setup and execution as before\n",
    "algorithm = NSGA2(\n",
    "    pop_size=10,\n",
    "    sampling=FloatRandomSampling(),\n",
    "    crossover=SBXCrossover(prob=0.9, eta=15),\n",
    "    mutation=PolynomialMutation(prob=0.1, eta=20)\n",
    ")\n",
    "\n",
    "# Assuming other parts of the code are unchanged\n",
    "\n",
    "# Execute the optimization\n",
    "result = minimize(problem,\n",
    "                  algorithm,\n",
    "                  termination=('n_gen', 200),\n",
    "                  seed=1,\n",
    "                  save_history=True,\n",
    "                  verbose=True)\n",
    "\n",
    "# Instead of using np.argmin(result.F), which assumes a single objective or that all solutions are feasible,\n",
    "# you should select the best solution considering the nature of your multi-objective optimization.\n",
    "# For instance, you might want to look at the Pareto front and select a solution from there.\n",
    "\n",
    "# Check if result has any feasible solution\n",
    "\n",
    "# Assuming the rest of your code is unchanged and you have the best_vector from the optimization\n",
    "if result.F.size > 0:\n",
    "    best_index = np.argmin(result.F)  # Get the index of the best solution\n",
    "\n",
    "    # Check if result.X is 1-dimensional or 2-dimensional\n",
    "    if result.X.ndim == 1:\n",
    "        best_vector = result.X  # If it's 1D, the whole array is the solution\n",
    "    else:\n",
    "        best_vector = result.X[best_index, :]  # If it's 2D, access the specific solution\n",
    "\n",
    "    print(\"Best vector:\", best_vector)\n",
    "else:\n",
    "    print(\"No solution found in the result.\")\n",
    "\n",
    "# Define the file path where you want to save the best vector\n",
    "#file_path = 'best_vector.txt'\n",
    "\n",
    "# Save the best vector to a text file\n",
    "#with open(file_path, 'w') as f:\n",
    "    # Convert each element in the vector to a string and join them with a newline character for full length\n",
    "    #f.write('\\n'.join(map(str, best_vector)))\n",
    "\n",
    "#print(f\"Best vector saved to {file_path}\")\n",
    "# Convert the list to a string representation\n",
    "sentence_vector = torch.tensor(best_vector, dtype=torch.float32).to(device).unsqueeze(0)  # Add batch dimension\n",
    "fingerprint_vector = predict_fingerprint(sentence_vector, model, device)\n",
    "\n",
    "            # Convert the fingerprint vector to a string representation\n",
    "best_str = ','.join(str(int(bit)) for bit in fingerprint_vector.squeeze().tolist())\n",
    "\n",
    "#best_str = ','.join(str(int(bit)) for bit in best_vector) \n",
    "\n",
    "# Define the command and arguments in a list\n",
    "command = [\n",
    "    'python', 'run_EEGSDE_fingerprint.py',\n",
    "    '--exp_name', 'eegsde_qm9_fingerprint',\n",
    "    '--l', '0.5',\n",
    "    '--generators_path', 'pretrained_models/cEDM_fingerprint/generative_model_ema_1340.npy',\n",
    "    '--args_generators_path', 'pretrained_models/cEDM_fingerprint/args_1340.pickle',\n",
    "    '--energy_path', 'pretrained_models/predict_fingerprint/model_ema_1750.npy',\n",
    "    '--args_energy_path', 'pretrained_models/predict_fingerprint/args_1750.pickle',\n",
    "    '--batch_size', '50',\n",
    "    '--save', 'True',\n",
    "    '--fp_1024', best_str  # Passing the string representation of the list\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print('Command failed')\n",
    "    print(result.stderr)\n",
    "else:\n",
    "    output_lines = result.stdout.split('\\n')\n",
    "    for line in output_lines:\n",
    "        if line.strip().endswith('_samples.xyz'):\n",
    "            print(f\"Generated molecule file path: {line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "76c9402d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES: C1C(O[C@@H]2[C@]3(C=C3)[C@@]2([CH]O)C)C1.[OH]\toutputs/eegsde_qm9_fingerprint/l_0.5/samples/70912/70912_samples.xyz/samples_000.txt\n",
      "Largest fragment SMILES: C[C@@]1([CH]O)[C@H](OC2CC2)C12C=C2\n",
      "Molecule is chemically valid.\n",
      "Properties:\n",
      "QED: 0.6441143857722531\n",
      "LogP: 1.64439\n",
      "MolWt: 165.21199999999996\n",
      "SA_Score: 3\n"
     ]
    }
   ],
   "source": [
    "import openbabel\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import QED, Crippen, Descriptors, rdMolDescriptors\n",
    "\n",
    "def xyz_to_smiles(xyz_file):\n",
    "    obConversion = openbabel.OBConversion()\n",
    "    obConversion.SetInFormat(\"xyz\")\n",
    "\n",
    "    mol = openbabel.OBMol()\n",
    "    obConversion.ReadFile(mol, xyz_file)  # Read the molecule from file\n",
    "\n",
    "    obConversion.SetOutFormat(\"smi\")\n",
    "    smiles = obConversion.WriteString(mol)  # Convert to SMILES\n",
    "\n",
    "    return smiles.strip()\n",
    "\n",
    "def get_largest_fragment(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if not mol:\n",
    "        return None, \"Invalid SMILES string.\"\n",
    "    \n",
    "    fragments = Chem.GetMolFrags(mol, asMols=True)\n",
    "    if not fragments:\n",
    "        return None, \"No fragments found.\"\n",
    "\n",
    "    largest_fragment = max(fragments, key=lambda frag: frag.GetNumAtoms())\n",
    "    return largest_fragment, \"\"\n",
    "\n",
    "def check_molecule_sanity(mol):\n",
    "    try:\n",
    "        Chem.SanitizeMol(mol)\n",
    "        return \"Molecule is chemically valid.\"\n",
    "    except Exception as e:\n",
    "        return f\"Sanity check failed: {e}\"\n",
    "\n",
    "def compute_properties(mol):\n",
    "    properties = {}\n",
    "    properties['QED'] = QED.qed(mol)\n",
    "    properties['LogP'] = Crippen.MolLogP(mol)\n",
    "    properties['MolWt'] = Descriptors.MolWt(mol)\n",
    "    properties['SA_Score'] = rdMolDescriptors.CalcNumRotatableBonds(mol)\n",
    "    return properties\n",
    "\n",
    "# Example usage\n",
    "xyz_file_path = 'outputs/eegsde_qm9_fingerprint/l_0.5/samples/70912/70912_samples.xyz/samples_000.txt'\n",
    "smiles = xyz_to_smiles(xyz_file_path)\n",
    "print(\"SMILES:\", smiles)\n",
    "\n",
    "largest_fragment, message = get_largest_fragment(smiles)\n",
    "if largest_fragment:\n",
    "    print(\"Largest fragment SMILES:\", Chem.MolToSmiles(largest_fragment))\n",
    "    validity_message = check_molecule_sanity(largest_fragment)\n",
    "    print(validity_message)\n",
    "    \n",
    "    if \"chemically valid\" in validity_message:\n",
    "        properties = compute_properties(largest_fragment)\n",
    "        print(\"Properties:\")\n",
    "        for prop, value in properties.items():\n",
    "            print(f\"{prop}: {value}\")\n",
    "else:\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18601bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original SMILES: C1=C[C@@H]([C@@H](C(=C1)C(=O)O)O)O\t/home/chao/3dmolgen/data/small_mol_5/3.xyz\n",
      "Original largest fragment SMILES: O=C(O)C1=CC=C[C@H](O)[C@@H]1O\n",
      "Molecule is chemically valid.\n",
      "Original Properties:\n",
      "QED: 0.4682894606480587\n",
      "LogP: -0.7110000000000001\n",
      "MolWt: 156.137\n",
      "SA_Score: 1\n",
      "\n",
      "Property Differences (Loss):\n",
      "QED Loss: 0.17133286990058555\n",
      "LogP Loss: 2.53288\n",
      "MolWt Loss: 3.900000000000034\n",
      "SA_Score Loss: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Assume xyz_to_smiles, get_largest_fragment, check_molecule_sanity, and compute_properties functions are already defined\n",
    "\n",
    "# Define the paths\n",
    "ground_truth_dir = '/home/chao/3dmolgen/data/small_mol_5'\n",
    "original_xyz_file = os.path.join(ground_truth_dir, '3.xyz')\n",
    "\n",
    "# Process the original molecule\n",
    "original_smiles = xyz_to_smiles(original_xyz_file)\n",
    "print(\"Original SMILES:\", original_smiles)\n",
    "\n",
    "original_fragment, message = get_largest_fragment(original_smiles)\n",
    "if original_fragment:\n",
    "    print(\"Original largest fragment SMILES:\", Chem.MolToSmiles(original_fragment))\n",
    "    validity_message = check_molecule_sanity(original_fragment)\n",
    "    print(validity_message)\n",
    "    \n",
    "    if \"chemically valid\" in validity_message:\n",
    "        original_properties = compute_properties(original_fragment)\n",
    "        print(\"Original Properties:\")\n",
    "        for prop, value in original_properties.items():\n",
    "            print(f\"{prop}: {value}\")\n",
    "else:\n",
    "    print(message)\n",
    "\n",
    "# Assuming 'properties' contains the properties of the generated molecule\n",
    "# Calculate and print the loss between the original and generated properties\n",
    "if 'properties' in locals() and 'original_properties' in locals():\n",
    "    print(\"\\nProperty Differences (Loss):\")\n",
    "    for prop in properties.keys():\n",
    "        loss = abs(properties[prop] - original_properties[prop])\n",
    "        print(f\"{prop} Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7110494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EEGSDE",
   "language": "python",
   "name": "eegsde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
